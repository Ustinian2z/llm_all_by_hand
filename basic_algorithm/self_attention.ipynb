{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7ea17ea",
   "metadata": {},
   "source": [
    "### Attention\n",
    "\n",
    "Attention(Q,K,V)=softmax(QK^T/sqrt{d_k}) V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af281a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5698c75",
   "metadata": {},
   "source": [
    "### 第一个：最基本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb74ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4944, 0.5056],\n",
      "         [0.4882, 0.5118]],\n",
      "\n",
      "        [[0.5005, 0.4995],\n",
      "         [0.5007, 0.4993]],\n",
      "\n",
      "        [[0.4920, 0.5080],\n",
      "         [0.4928, 0.5072]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4451, 0.4225, 0.3530, 1.3451],\n",
       "         [0.4440, 0.4240, 0.3538, 1.3457]],\n",
       "\n",
       "        [[0.2375, 0.3486, 0.2302, 1.1640],\n",
       "         [0.2374, 0.3486, 0.2301, 1.1639]],\n",
       "\n",
       "        [[0.2624, 0.1932, 0.2074, 1.0387],\n",
       "         [0.2619, 0.1932, 0.2071, 1.0385]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### self_attention_v1\n",
    "\n",
    "class SelfAttentionV1(nn.Module):\n",
    "    def __init__(self, hidden_dim: int = 728):\n",
    "        super().__init__()  # 初始化\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.query_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape is: (batch_size, seq_len, hidden_dim)\n",
    "        Q = self.query_proj(x)\n",
    "        K = self.key_proj(x)\n",
    "        V = self.value_proj(x)\n",
    "        # Q, K, V shape is: (batch_size, seq_len, hidden_dim)\n",
    "        # attention_value shape is: (batch_size, seq_len, seq_len)\n",
    "        attention_value = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.hidden_dim)\n",
    "        attention_weight = torch.softmax(attention_value, dim=-1)   # 注意指定维度\n",
    "        print(attention_weight)\n",
    "\n",
    "        # 最后shape is (batch_size, seq_len, hidden_dim)\n",
    "        output = torch.matmul(attention_weight, V)\n",
    "        return output\n",
    "\n",
    "X = torch.rand(3,2,4)\n",
    "\n",
    "net_att_net = SelfAttentionV1(hidden_dim=4)\n",
    "net_att_net(X)  # 这里forward方法会被自动调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b897d0",
   "metadata": {},
   "source": [
    "### 第二个：效率优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a529f7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5722, 0.4278],\n",
      "         [0.5571, 0.4429]],\n",
      "\n",
      "        [[0.5515, 0.4485],\n",
      "         [0.5443, 0.4557]],\n",
      "\n",
      "        [[0.4959, 0.5041],\n",
      "         [0.4671, 0.5329]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6875,  0.0884,  0.2283,  0.0983],\n",
       "         [ 0.6863,  0.0922,  0.2344,  0.0992]],\n",
       "\n",
       "        [[ 0.6300,  0.2246,  0.4552,  0.0222],\n",
       "         [ 0.6283,  0.2223,  0.4568,  0.0220]],\n",
       "\n",
       "        [[ 0.5063,  0.1050,  0.2852, -0.0276],\n",
       "         [ 0.5021,  0.1134,  0.2738, -0.0379]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 小网络的优化的self_attention\n",
    "\n",
    "class SelfAttentionV2(nn.Module):\n",
    "    def __init__(self, hidden_dim: int = 728):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.proj = nn.Linear(hidden_dim, hidden_dim * 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        QKV = self.proj(x)\n",
    "        Q, K, V = torch.split(QKV, self.hidden_dim, dim=-1)\n",
    "        # 将 QKV 张量在最后一个维度上按每 self.hidden_dim 个元素为一组进行分割，最终得到三个形状为 [..., hidden_dim] 的张量，分别赋值给 Q, K, V。\n",
    "        attn_weight = torch.softmax(\n",
    "            torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.hidden_dim), dim = -1\n",
    "        )\n",
    "        print(attn_weight)\n",
    "        output = attn_weight @ V\n",
    "        return output\n",
    "\n",
    "X = torch.rand(3,2,4)\n",
    "\n",
    "net_att_net = SelfAttentionV2(hidden_dim=4)\n",
    "net_att_net(X)  # 这里forward方法会被自动调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69639ed1",
   "metadata": {},
   "source": [
    "### 第三个：加入细节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7196e9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat mask shape: torch.Size([3, 4, 4])\n",
      "tensor([[[0.3502, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3440, 0.3924, 0.3747, 0.0000],\n",
      "         [0.3467, 0.4061, 0.3583, 0.0000],\n",
      "         [0.3523, 0.3831, 0.3757, 0.0000]],\n",
      "\n",
      "        [[0.5272, 0.5839, 0.0000, 0.0000],\n",
      "         [0.5229, 0.5882, 0.0000, 0.0000],\n",
      "         [0.5282, 0.5829, 0.0000, 0.0000],\n",
      "         [0.5480, 0.5631, 0.0000, 0.0000]],\n",
      "\n",
      "        [[1.1111, 0.0000, 0.0000, 0.0000],\n",
      "         [1.1111, 0.0000, 0.0000, 0.0000],\n",
      "         [1.1111, 0.0000, 0.0000, 0.0000],\n",
      "         [1.1111, 0.0000, 0.0000, 0.0000]]], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6183, 0.0695],\n",
       "         [0.5161, 0.8021],\n",
       "         [0.5184, 0.7953],\n",
       "         [0.5156, 0.8029]],\n",
       "\n",
       "        [[0.4883, 0.9489],\n",
       "         [0.4885, 0.9484],\n",
       "         [0.4882, 0.9490],\n",
       "         [0.4871, 0.9512]],\n",
       "\n",
       "        [[0.4920, 0.9602],\n",
       "         [0.4920, 0.9602],\n",
       "         [0.4920, 0.9602],\n",
       "         [0.4920, 0.9602]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. dropout 位置\n",
    "# 2. attention_mask：每个句子长度不一，要加入pad\n",
    "# 3. output 矩阵projection\n",
    "\n",
    "class SelfAttentionV3(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout_rate = 0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.proj = nn.Linear(hidden_dim, hidden_dim * 3)\n",
    "        self.attention_dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # 可选\n",
    "        self.output_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, x, attention_mask = None):\n",
    "        QKV = self.proj(x)\n",
    "        Q, K, V = torch.split(QKV, self.hidden_dim, dim=-1)\n",
    "\n",
    "        attn_weight = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.hidden_dim)\n",
    "        if attention_mask is not None:\n",
    "            attn_weight = attn_weight.masked_fill(attention_mask == 0, float('-inf'))\n",
    "        \n",
    "        attn_weight = torch.softmax(attn_weight, dim=-1)\n",
    "        # 在weight层面做dropout，相当于不关注有些词\n",
    "        attn_weight = self.attention_dropout(attn_weight)\n",
    "        print(attn_weight)\n",
    "\n",
    "        attn_result = attn_weight @ V\n",
    "\n",
    "        output = self.output_proj(attn_result)\n",
    "        return output\n",
    "    \n",
    "\n",
    "X = torch.rand(3,4,2)\n",
    "# 希望是(batch_size, seq_len, seq_len)的，但现在只是(batch_size, seq_len)的\n",
    "mask = torch.tensor(\n",
    "    [\n",
    "        [1, 1, 1, 0], # 第一个句子长度为3\n",
    "        [1, 1, 0, 0], # 第二个句子长度为2\n",
    "        [1, 0, 0, 0]  # 第三个句子长度为1\n",
    "    ]\n",
    ")\n",
    "# repeat用法：维度0不用repeat，维度1重复seq_len次，维度2不变\n",
    "mask = mask.unsqueeze(dim=1).repeat(1, X.shape[1], 1)  # 扩展到(batch_size, seq_len, seq_len)\n",
    "print(f\"repeat mask shape: {mask.shape}\")\n",
    "\n",
    "net_att_net = SelfAttentionV3(hidden_dim=2)\n",
    "net_att_net(X, mask)  # 这里forward方法会被自动调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe2353c",
   "metadata": {},
   "source": [
    "### 第4个：面试写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a4738e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat mask shape: torch.Size([3, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2154,  0.8047],\n",
       "         [-1.2120,  0.8057],\n",
       "         [-1.2121,  0.8053],\n",
       "         [-0.8528,  0.5364]],\n",
       "\n",
       "        [[-1.0856,  0.7826],\n",
       "         [-1.0956,  0.7827],\n",
       "         [-1.0888,  0.7826],\n",
       "         [-1.0962,  0.7827]],\n",
       "\n",
       "        [[-1.0918,  0.8578],\n",
       "         [-1.0918,  0.8578],\n",
       "         [-1.0918,  0.8578],\n",
       "         [-1.0918,  0.8578]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SelfAttentionV4(nn.Module):\n",
    "    def __init__(self, dim: int, dropout_rate: float = 0.1) -> None:\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.query = nn.Linear(dim, dim)\n",
    "        self.key = nn.Linear(dim, dim)\n",
    "        self.value = nn.Linear(dim, dim)\n",
    "\n",
    "        self.attn_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, attn_mask = None):\n",
    "        # X shape is: (batch_size, seq_len, dim)\n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "        \n",
    "        attn_weight = Q @ K.transpose(-2, -1) / math.sqrt(self.dim)\n",
    "        if attn_mask is not None:\n",
    "            attn_weight = attn_weight.masked_fill(\n",
    "                attn_mask == 0, float('-inf')\n",
    "            )\n",
    "\n",
    "        attn_weight = torch.softmax(attn_weight, dim=-1)\n",
    "        attn_weight = self.attn_dropout(attn_weight)\n",
    "        output = attn_weight @ V\n",
    "        return output\n",
    "\n",
    "\n",
    "X = torch.rand(3,4,2)\n",
    "# 希望是(batch_size, seq_len, seq_len)的，但现在只是(batch_size, seq_len)的\n",
    "mask = torch.tensor(\n",
    "    [\n",
    "        [1, 1, 1, 0], # 第一个句子长度为3\n",
    "        [1, 1, 0, 0], # 第二个句子长度为2\n",
    "        [1, 0, 0, 0]  # 第三个句子长度为1\n",
    "    ]\n",
    ")\n",
    "# repeat用法：维度0不用repeat，维度1重复seq_len次，维度2不变\n",
    "mask = mask.unsqueeze(dim=1).repeat(1, X.shape[1], 1)  # 扩展到(batch_size, seq_len, seq_len)\n",
    "print(f\"repeat mask shape: {mask.shape}\")\n",
    "\n",
    "net_att_net = SelfAttentionV4(dim=2)\n",
    "net_att_net(X, mask)  # 这里forward方法会被自动调用\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-all-by-hand (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
