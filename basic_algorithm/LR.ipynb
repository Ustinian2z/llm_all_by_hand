{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e78c3f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ceb307c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss: 0.6931471805599453\n",
      "Iteration 100, loss: 0.5785085057822918\n",
      "Iteration 200, loss: 0.5101523134039823\n",
      "Iteration 300, loss: 0.45569542496216126\n",
      "Iteration 400, loss: 0.41178408708668\n",
      "Iteration 500, loss: 0.375887072920645\n",
      "Iteration 600, loss: 0.3461301007463976\n",
      "Iteration 700, loss: 0.32113124406621973\n",
      "Iteration 800, loss: 0.2998672766461169\n",
      "Iteration 900, loss: 0.28157381490682754\n",
      "[ 1.30487443 -0.58558045] -1.2931549586737172\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid 函数\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# 损失函数：交叉熵\n",
    "def compute_loss(y, y_hat):\n",
    "    m = len(y)\n",
    "    loss = -np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)) / m\n",
    "    return loss\n",
    "\n",
    "# 梯度下降\n",
    "def logistic_regression(X, y, learning_rate = 0.01, num_iteration = 1000):\n",
    "    m, n = X.shape\n",
    "    w = np.zeros(n)\n",
    "    b = 0\n",
    "    loss_history = []\n",
    "\n",
    "    for i in range(num_iteration):\n",
    "        # 计算线性模型输出\n",
    "        z = np.dot(X, w) + b\n",
    "        y_hat = sigmoid(z)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = compute_loss(y, y_hat)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        # 计算梯度,注意sigmoid导数为y_hat * (1 - y_hat)，然后链式法则可以得到\n",
    "        dw = np.dot(X.T, (y_hat - y)) / m \n",
    "        db = np.sum(y_hat - y) / m \n",
    "\n",
    "        # 更新参数\n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}, loss: {loss}\")\n",
    "    \n",
    "    return w, b, loss_history\n",
    "\n",
    "X = np.array([[1, 2], [1, 3], [2, 3], [4, 5], [6, 7]])    # 输入2个特征\n",
    "y = np.array([0, 0, 0, 1, 1])   # 真实标签\n",
    "\n",
    "w, b, loss_history = logistic_regression(X, y)\n",
    "\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf70a840",
   "metadata": {},
   "source": [
    "### 交叉熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eddc18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Cross-Entropy Loss: 0.20273661557656092\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    # 方法1\n",
    "    m = y_true.shape[0]\n",
    "    loss = - np.sum((y_true * np.log(y_pred)) + (1- y_true) * np.log(1- y_pred)) / m\n",
    "    return loss\n",
    "\n",
    "    # 方法2\n",
    "    loss = - (y_true * np.log(y_pred)) + (1- y_true) * np.log(1 - y_pred)\n",
    "    return np.mean(loss)\n",
    "\n",
    "# 示例：真实标签和预测概率\n",
    "y_true = np.array([1, 0, 1, 1, 0])\n",
    "y_pred = np.array([0.9, 0.1, 0.8, 0.7, 0.2])\n",
    "\n",
    "# 计算交叉熵损失\n",
    "loss = binary_cross_entropy(y_true, y_pred)\n",
    "print(f\"Binary Cross-Entropy Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3abeb5",
   "metadata": {},
   "source": [
    "### 多分类交叉熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9fec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3) (5, 3)\n",
      "Categorical Cross-Entropy Loss: 0.2571233586732892\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def categorical_cross_entropy(y_true, y_pred):\n",
    "    # shape (batch_size, num_classes)\n",
    "    # 防止log(0)的情况，对预测概率做裁剪\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1-epsilon)\n",
    "\n",
    "    loss = -np.sum(y_true * np.log(y_pred), axis=1)\n",
    "    return np.mean(loss)    # 注意这里还是要用mean！因为上面的np.sum只是二维转一维\n",
    "\n",
    "# 三个类别，one-hot编码\n",
    "y_true = np.array([[0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0]])\n",
    "y_pred = np.array([[0.1, 0.8, 0.1], [0.9, 0.05, 0.05], [0.1, 0.1, 0.8], [0.3, 0.6, 0.1], [0.8, 0.1, 0.1]])\n",
    "\n",
    "print(y_true.shape, y_pred.shape)\n",
    "\n",
    "loss = categorical_cross_entropy(y_true, y_pred)\n",
    "print(f\"Categorical Cross-Entropy Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f729a4",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6852cd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Output: [4.86939638 1.79135082 0.72830889]\n",
      "Softmax Derivative Matrix:\n",
      " [[-18.84162476  -8.72279721  -3.54642469]\n",
      " [ -8.72279721  -1.41758694  -1.30465673]\n",
      " [ -3.54642469  -1.30465673   0.19787505]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 注意softmax是归一化，sigmoid是激活函数\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z))   # 减去最大值防止溢出\n",
    "    return np.exp(z) / np.sum(exp_z)\n",
    "\n",
    "def softmax_derivative(z):\n",
    "    p = softmax(z)\n",
    "    S = np.diag(p) - np.outer(p,p)\n",
    "    return S\n",
    "\n",
    "# 示例\n",
    "\n",
    "z = np.array([2.0, 1.0, 0.1])  # 模型的输出（未归一化的得分）\n",
    "softmax_output = softmax(z)\n",
    "softmax_derivative_output = softmax_derivative(z)\n",
    "\n",
    "print(\"Softmax Output:\", softmax_output)\n",
    "print(\"Softmax Derivative Matrix:\\n\", softmax_derivative_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_byhand3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
